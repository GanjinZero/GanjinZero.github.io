<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="GanjinZero.github.io">
<meta property="og:url" content="https://ganjinzero.github.io/index.html">
<meta property="og:site_name" content="GanjinZero.github.io">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GanjinZero.github.io">






  <link rel="canonical" href="https://ganjinzero.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>GanjinZero.github.io</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">GanjinZero.github.io</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ganjinzero.github.io/2019/03/26/科学麻将：从不放炮开始/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="GanjinZero">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GanjinZero.github.io">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/26/科学麻将：从不放炮开始/" class="post-title-link" itemprop="url">科学麻将：从不放炮开始</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-26 15:34:00" itemprop="dateCreated datePublished" datetime="2019-03-26T15:34:00+08:00">2019-03-26</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-28 12:21:09" itemprop="dateModified" datetime="2019-03-28T12:21:09+08:00">2019-03-28</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h1><p><a href="https://github.com/GanjinZero/Tenpai_prediction" target="_blank" rel="noopener">https://github.com/GanjinZero/Tenpai_prediction</a></p>
<h1 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h1><p>日本麻将是一种最强调防守的麻将，它比其他的麻将更注重不要点炮（也就是放铳）。雀魂最近比较流行，所以我又重新开始玩日麻（以前在MJ和天凤都打过一点）。我也比较菜，才打到雀士三。一个经常遇到的场景时，当有人立直（门清宣告听牌）的时候，当我选择弃胡时，我想知道应该打出什么样的牌才不会点炮。这就是在这个项目中研究的问题：当他家率先立直时，他家可能的听牌有哪些。这个问题可以看成是一个文本分类问题来考虑，将前面已经打过的牌当作文本，听牌考虑成文本最终的分类。当然这还是和文本分类问题不太一样的，因为对于某一个文本一般是固定一个分类（比如情感分类中的积极或者消极）；而对于麻将而言首先一次听牌可以听好几种牌（纯正九莲宝灯！）、其次同样的舍牌可能听的牌完全不同。</p>
<p>在这里推荐一本书《科学するマジャン》，可以在苹果的图书商店下载到。这里有利用概率论计算的麻将打法和一些关于麻将的数值模拟结果。本项目也是在阅读该书中产生的想法。</p>
<p><img src="/images/big_hand.gif" alt="听说你在做大牌"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ロン!断幺九!30符1番,1000点!</span><br></pre></td></tr></table></figure>
<h1 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h1><h2 id="牌谱收集"><a href="#牌谱收集" class="headerlink" title="牌谱收集"></a>牌谱收集</h2><p>最初是在《科学する麻雀》中看到了该书作者とつげき東北的<a href="http://totutohoku.b23.coreserver.jp/hp/" target="_blank" rel="noopener">个人主页</a>，然后在这面找到他收集的一些在东风庄这个平台上的一些<a href="http://totutohoku.b23.coreserver.jp/hp/HAIHU.htm" target="_blank" rel="noopener">牌谱</a>。</p>
<p><a href=""><img src="/images/kagakusuru.jpg" alt="kagakul"></a></p>
<p>一共收集有万份左右的牌谱。</p>
<p>一份牌谱的示例如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">東2局 0本場(リーチ0) YZKTR 3000 松戸の俊 -1500 菌太郎 -1000 シャモア -500 </span><br><span class="line">  30符 二飜ツモ リーチ 門前清模和 </span><br><span class="line">  [1西]3p8p9p3s4s8s8s南西北白白発</span><br><span class="line">  [2北]1m5m6m7m4p6p1s5s7s東白白中</span><br><span class="line">  [3東]3m5m2p3p4p6p8p9p1s5s7s8s8s</span><br><span class="line">  [4南]1m4m4m9m1p5p5p7p9p4s4s北中</span><br><span class="line">  [表ドラ]西 [裏ドラ]北</span><br><span class="line">  * 3G9s 3D9s 4G中 4d9m 1G8m 1d北 2G4m 2d1s 3G6p 3D6p 4G1p 4d1m</span><br><span class="line">  * 1G6s 1d南 2G2s 2d1m 3G6s 3D6s 4G2s 4D2s 1C3s4s 1d8m 2C6m7m 2d2s</span><br><span class="line">  * 3G3s 3G3s 4G7p 4d9p 4R 1G3s 1d9p</span><br></pre></td></tr></table></figure>
<p>这里记录了对局信息，胡牌的番型和各家起手牌、宝牌、每家每一轮的摸牌、切牌和鸣牌。这些牌谱的具体信息会在下文的<strong>牌谱准备</strong>中详细介绍。4R代表南家立直，那么对于东、西、北家都需要预测南家可能的听牌。因为各家的起手牌不同，摸到的牌也不同，所以对于南家的听牌有不同的估计（在德扑中叫做阻隔牌）。三家由于有不同的起手信息，所以可以生成三份训练数据。例如对于北家而言，可以只留下北家可以知道的信息作为训练用的x，而将南家的真实听牌作为训练用的y。</p>
<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>只用这些牌谱数据看起来还有些不够，训练出的结果不是很理想。考虑可以这样生成一些假的牌谱。将中、发、白以某种顺序置换；将饼、万、索以某种顺序置换；将123456789变成987654321。这样的变换不能保证是完全合理的。一个原因是绿一色导致索和饼、万并不是完全等价的，但考虑到绿一色出现的概率如此的低就不管了。另一个原因是宝牌的问题，比如原来的宝牌指示牌是1m，宝牌是2m。如果进行了123456789变成987654321，宝牌就会变成8m；这时宝牌指示牌并不能变成9m，而变成了7m。这两个问题不能很好解决，但为了获得更多的牌谱，还是进行了这几种置换。中发白的置换共6种，饼万索的置换共6种，数字颠倒共2种（颠倒或者不颠倒），一共6*6*2=72种变换方式。对每一份牌谱，我们随机的选择k=7种变换作为增强的数据。（考虑到内存大小，k不要太大）</p>
<h2 id="将牌谱编码"><a href="#将牌谱编码" class="headerlink" title="将牌谱编码"></a>将牌谱编码</h2><p>我们将每一次摸牌，鸣牌或者打牌都定义为一个action，然后将这个action嵌入到一个52维向量中。这个向量描述了这个动作是谁执行的（东西南北家），是进行了什么动作（摸牌、切牌、吃碰杠、立直），是和哪一张牌进行了交互，交互牌是否是自风、场风、宝牌这些信息。具体的编码方式可以看<strong>/src/haifu_parser.py</strong>中的<strong>action_to_vector(action, player, chanfon, jikaze, dora_list)</strong>函数。</p>
<h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><p>模型使用了双层LSTM网络连接34维的Softmax层进行预测（麻将一共34张不同的牌）。损失函数为交叉熵。在两块1080Ti的显卡下训练70个epoch得到了预训练的模型，大约需要训练2个小时。具体的模型可以参照<strong>/src/neural_network.py</strong>中的结构。</p>
<h1 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h1><h2 id="预备工作"><a href="#预备工作" class="headerlink" title="预备工作"></a>预备工作</h2><p>需要有可以编译Python3的环境。在终端中输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/GanjinZero/Tenpai_prediction.git</span><br></pre></td></tr></table></figure></p>
<p>下载该项目。在终端中输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install -r requirements.txt</span><br></pre></td></tr></table></figure></p>
<p>安装依赖。</p>
<h2 id="牌谱准备"><a href="#牌谱准备" class="headerlink" title="牌谱准备"></a>牌谱准备</h2><p>预训练好的模型保存在<strong>model/tenpai.model</strong>。我们需要将牌谱设置为<strong>data/test.txt</strong>中的格式，并保存到<strong>data/test.txt</strong>中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">東2局 0本場(リーチ0)</span><br><span class="line">  123</span><br><span class="line">  [1西]</span><br><span class="line">  [2北]1m5m6m7m4p6p1s5s7s東白白中</span><br><span class="line">  [3東]</span><br><span class="line">  [4南]</span><br><span class="line">  [表ドラ]西 [裏ドラ]北</span><br><span class="line">  * 3D9s 4d9m 1d北 2G4m 2d1s 3D6p 4d1m</span><br><span class="line">  * 1d南 2G2s 2d1m 3D6s 4D2s 1C3s4s 1d8m 2C6m7m 2d2s</span><br><span class="line">  * 3D3s 4d9p 4R 1G3s 1d9p</span><br></pre></td></tr></table></figure></p>
<ul>
<li>第一行填写东x局（或者南x局），后面的本场、立直棒、点棒信息都不是必要的。</li>
<li>第二行填写符数、翻数、番形，可以留空行，但不能把这行都删了。</li>
<li><p>第三-六行填写四家起手牌，可以只填自家牌，其他留空。其中m代表万，p代表饼，s代表索；“東南西北中発白”请使用日语汉字。比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[1西]</span><br><span class="line">[2北]1m5m6m7m4p6p1s5s7s東白白中</span><br><span class="line">[3東]</span><br><span class="line">[4南]</span><br></pre></td></tr></table></figure>
</li>
<li><p>第七行填写宝牌和里宝牌，里宝牌可以不填。注意是宝牌，不是宝牌指示牌！</p>
</li>
<li>第八行起填写这局牌的行进过程。每一行以*开始，每一个行动和行动之间有一个空格。比如第一行的动作3D9s可以翻译为东家摸切9s，4d9m可以翻译为3家切掉9m。只需要记录自家的摸牌动作（在这里就是2G，因为其他家摸到的牌你是看不见的，就算输入了模型也会忽略其他家的摸牌数据）完整的动作对应表见下表：<br>| 字符 |  含义 | 用法示例 |<br>| :———-: | :————————: | :————————: |<br>|     G     | 自摸（不是自摸和）  | 1G1m |<br>|     d     |        切牌        |        1d2s        |<br>|     D     |        摸切        |        1D1m        |<br>|     N     |        碰        |        1N        |<br>|     C     |        吃        |        1C1s3s（1s3s是玩家1自己的牌）        |<br>|     K     |        杠        |        1K1s        |<br>|     R     |       立直       |       1R       |<br>|     A     |       胡牌       |       1A       |</li>
</ul>
<p><strong>data/test.txt</strong>中可以保存多个牌谱，请在牌谱和牌谱之间用空行分隔。</p>
<p>P.S. 如果可以直接获取到文字格式的天凤或者雀魂牌谱，可以编写一个牌谱的自动encoder，就不需要上述这么麻烦了。</p>
<h2 id="开始预测"><a href="#开始预测" class="headerlink" title="开始预测"></a>开始预测</h2><p>在<strong>src</strong>文件夹下，使用如下的命令进行预测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python predict.py</span><br></pre></td></tr></table></figure>
<p>就可以看到类似如下的预测结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Richi player tenpai: [&apos;3m&apos;, &apos;6m&apos;, &apos;9m&apos;]</span><br><span class="line">Player 1: </span><br><span class="line">&#123;&apos;3m&apos;: 0.33759603, &apos;6m&apos;: 0.33912653, &apos;9m&apos;: 0.32323775&#125;</span><br><span class="line">Richi player tenpai: [&apos;3m&apos;, &apos;6m&apos;, &apos;9m&apos;]</span><br><span class="line">Player 2: </span><br><span class="line">&#123;&apos;3m&apos;: 0.337948, &apos;6m&apos;: 0.33527905, &apos;9m&apos;: 0.31589714&#125;</span><br><span class="line">Richi player tenpai: [&apos;3m&apos;, &apos;6m&apos;, &apos;9m&apos;]</span><br><span class="line">Player 3: </span><br><span class="line">&#123;&apos;3m&apos;: 0.33415237, &apos;6m&apos;: 0.33977884, &apos;9m&apos;: 0.32597464&#125;</span><br><span class="line">Richi player tenpai: [&apos;6m&apos;]</span><br></pre></td></tr></table></figure>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>欢迎提供更多的牌谱和咖啡给作者！联系作者：</p>
<p><a href="https://github.com/GanjinZero/" target="_blank" rel="noopener">Github</a> - <a href="https://github.com/GanjinZero/" target="_blank" rel="noopener">https://github.com/GanjinZero/</a></p>
<p>Email - <a href="&#109;&#97;&#x69;&#108;&#116;&#111;&#x3a;&#x79;&#x75;&#97;&#x6e;&#x7a;&#x31;&#x37;&#64;&#109;&#x61;&#x69;&#108;&#x73;&#46;&#x74;&#115;&#105;&#110;&#103;&#x68;&#117;&#97;&#46;&#101;&#100;&#117;&#46;&#99;&#110;">&#x79;&#x75;&#97;&#x6e;&#x7a;&#x31;&#x37;&#64;&#109;&#x61;&#x69;&#108;&#x73;&#46;&#x74;&#115;&#105;&#110;&#103;&#x68;&#117;&#97;&#46;&#101;&#100;&#117;&#46;&#99;&#110;</a></p>
<p><img src="/images/jyama.png" alt="Jyama"></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ganjinzero.github.io/2019/02/28/简易教程：使用Bert预训练模型文本分类/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="GanjinZero">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GanjinZero.github.io">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/28/简易教程：使用Bert预训练模型文本分类/" class="post-title-link" itemprop="url">教程：使用Bert预训练模型文本分类</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-02-28 11:40:38" itemprop="dateCreated datePublished" datetime="2019-02-28T11:40:38+08:00">2019-02-28</time>
            

            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Bert介绍"><a href="#Bert介绍" class="headerlink" title="Bert介绍"></a>Bert介绍</h1><p>Bert模型是Google在2018年10月发布的语言表示模型，Bert在NLP领域横扫了11项任务的最优结果，可以说是现今最近NLP中最重要的突破。Bert模型的全称是Bidirectional Encoder Representations from Transformers，是通过训练Masked Language Model和预测下一句任务得到的模型。关于Bert具体训练的细节和更多的原理，有兴趣的读者可以去看在<a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">arXiv</a>上的原文。本篇文章从实践入手，带领大家进行Bert的中文文本分类和作为句子向量进行使用的教程。</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>1.下载bert</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/google-research/bert.git</span><br></pre></td></tr></table></figure>
<p>2.下载bert预训练模型</p>
<p>Google提供了多种预训练好的bert模型，有针对不同语言的和不同模型大小的。对于中文模型，我们使用<a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" target="_blank" rel="noopener">Bert-Base, Chinese</a>。为了下载该模型，可能需要使用梯子。如果需要下载其他的模型(英文以及其他语言)，可以在<a href="https://github.com/google-research/bert" target="_blank" rel="noopener">Bert</a>里的Pre-trained models找到下载链接。</p>
<p>3.（可选项）安装bert-as-service，这是一个可以利用bert模型将句子映射到固定长度向量的服务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install bert-serving-server # server</span><br><span class="line">pip install bert-serving-client # client, independent of &apos;bert-serving-server&apos;</span><br></pre></td></tr></table></figure>
<p>该服务要求tensorflow的最低版本为1.10。</p>
<h1 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h1><h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><p>作为中文文本分类问题，需要先将数据集整理成可用的形式。不同的格式对应了不同的DataProcessor类。可以将数据保存成如下格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">game	APEX是个新出的吃鸡游戏。</span><br><span class="line">technology	Google将要推出tensorflow2.0。</span><br></pre></td></tr></table></figure>
<p>一行代表一个文本，由标签加上一个tab加上正文组成。</p>
<p>将文本分割为三个文件，train.tsv(训练集)，dev.tsv(验证集)，test.tsv(测试集)；然后放置在同一个data_dir文件夹下。</p>
<h2 id="编写DataProcessor类"><a href="#编写DataProcessor类" class="headerlink" title="编写DataProcessor类"></a>编写DataProcessor类</h2><p>在<strong>run_classifier.py</strong>中的<strong>def main(_):</strong>函数中将processors的内容增加为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">processors = &#123;</span><br><span class="line">      <span class="string">"cola"</span>: ColaProcessor,</span><br><span class="line">      <span class="string">"mnli"</span>: MnliProcessor,</span><br><span class="line">      <span class="string">"mrpc"</span>: MrpcProcessor,</span><br><span class="line">      <span class="string">"xnli"</span>: XnliProcessor,</span><br><span class="line">      <span class="string">"mytask"</span>: MyTaskProcessor,</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>实现如下的<strong>MyTaskProcessor(DataProcessor)</strong>类，并将这一段代码放置在<strong>run_classifier.py</strong>和其他Processor并列的位置。</p>
<p><strong>__init__(self)</strong>中的self.labels含有所有的分类label。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTaskProcessor</span><span class="params">(DataProcessor)</span>:</span></span><br><span class="line">    <span class="string">"""Processor for the News data set (GLUE version)."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.labels = [<span class="string">'game'</span>, <span class="string">'fashion'</span>, <span class="string">'houseliving'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_train_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._create_examples(</span><br><span class="line">            self._read_tsv(os.path.join(data_dir, <span class="string">"train.tsv"</span>)), <span class="string">"train"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_dev_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._create_examples(</span><br><span class="line">            self._read_tsv(os.path.join(data_dir, <span class="string">"dev.tsv"</span>)), <span class="string">"dev"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_test_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">    	<span class="keyword">return</span> self._create_examples(</span><br><span class="line">        	self._read_tsv(os.path.join(data_dir, <span class="string">"test.tsv"</span>)), <span class="string">"test"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_labels</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.labels</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_examples</span><span class="params">(self, lines, set_type)</span>:</span></span><br><span class="line">        <span class="string">"""Creates examples for the training and dev sets."""</span></span><br><span class="line">        examples = []</span><br><span class="line">        <span class="keyword">for</span> (i, line) <span class="keyword">in</span> enumerate(lines):</span><br><span class="line">            guid = <span class="string">"%s-%s"</span> % (set_type, i)</span><br><span class="line">            text_a = tokenization.convert_to_unicode(line[<span class="number">1</span>])</span><br><span class="line">            label = tokenization.convert_to_unicode(line[<span class="number">0</span>])</span><br><span class="line">            examples.append(</span><br><span class="line">                InputExample(guid=guid, text_a=text_a, text_b=<span class="keyword">None</span>, label=label))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>
<p>如果数据格式并不是一个label，一个tab，一段文本；则需要更改<strong>_create_examples()</strong>的实现。</p>
<h2 id="编写运行脚本"><a href="#编写运行脚本" class="headerlink" title="编写运行脚本"></a>编写运行脚本</h2><p>新建一个运行脚本文件名为<strong>run.sh</strong>，将文件内容编辑为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> DATA_DIR=/media/ganjinzero/Code/bert/data/</span><br><span class="line"><span class="built_in">export</span> BERT_BASE_DIR=/media/ganjinzero/Code/bert/chinese_L-12_H-768_A-12</span><br><span class="line"></span><br><span class="line">python run_classifier.py \</span><br><span class="line">  --task_name=mytask \</span><br><span class="line">  --do_train=<span class="literal">true</span> \</span><br><span class="line">  --do_eval=<span class="literal">true</span> \</span><br><span class="line">  --data_dir=<span class="variable">$DATA_DIR</span>/ \</span><br><span class="line">  --vocab_file=<span class="variable">$BERT_BASE_DIR</span>/vocab.txt \</span><br><span class="line">  --bert_config_file=<span class="variable">$BERT_BASE_DIR</span>/bert_config.json \</span><br><span class="line">  --init_checkpoint=<span class="variable">$BERT_BASE_DIR</span>/bert_model.ckpt \</span><br><span class="line">  --max_seq_length=128 \</span><br><span class="line">  --train_batch_size=32 \</span><br><span class="line">  --learning_rate=2e-5 \</span><br><span class="line">  --num_train_epochs=3.0 \</span><br><span class="line">  --output_dir=/mytask_output</span><br></pre></td></tr></table></figure>
<p>其中DATA_DIR是你的要训练的文本的数据所在的文件夹，BERT_BASE_DIR是你的bert预训练模型存放的地址。task_name要求和你的DataProcessor类中的名称一致。下面的几个参数，do_train代表是否进行fine tune，do_eval代表是否进行evaluation，还有未出现的参数do_predict代表是否进行预测。max_seq_length代表了句子的最长长度，当显存不足时，可以适当降低max_seq_length。</p>
<h1 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h1><p>运行脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./run.sh</span><br></pre></td></tr></table></figure>
<p>可以得到类似如下样式的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">***** Eval results *****</span><br><span class="line">  eval_accuracy = 0.845588</span><br><span class="line">  eval_loss = 0.505248</span><br><span class="line">  global_step = 343</span><br><span class="line">  loss = 0.505248</span><br></pre></td></tr></table></figure>
<p>如果出现了这样的输出，就是运行成功了。在<strong>run.sh</strong>里指定的output_dir文件夹下可以看到模型的evaluation结果和fine-tune之后的模型文件。</p>
<h1 id="以句子向量的形式使用Bert"><a href="#以句子向量的形式使用Bert" class="headerlink" title="以句子向量的形式使用Bert"></a>以句子向量的形式使用Bert</h1><p>如果想要将bert模型的编码和其他模型一起使用，将bert模型作为句子向量使用很有意义。我们可以使用bert-as-service来完成这个目标。</p>
<p>安装完bert-as-service以后，就可以利用bert模型将句子映射到固定长度的向量上。在终端中用一下命令启动服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bert-serving-start -model_dir /media/ganjinzero/Code/bert/chinese_L-12_H-768_A-12 -num_worker=4</span><br></pre></td></tr></table></figure>
<p>model_dir后面的参数是bert预训练模型所在的文件夹。num_worker的数量应该取决于你的CPU/GPU数量。</p>
<p>这时就可以在Python中调用如下的命令：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bert_serving.client <span class="keyword">import</span> BertClient</span><br><span class="line">bc = BertClient()</span><br><span class="line">bc.encode([<span class="string">'一二三四五六七八'</span>, <span class="string">'今天您吃了吗？'</span>])</span><br></pre></td></tr></table></figure>
<p>最好以列表的形式，而非单个字符串传给<strong>bc.encode()</strong>参数，这样程序运行的效率较高。</p>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://github.com/google-research/bert" target="_blank" rel="noopener">Github:bert</a></p>
<p><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">arXiv:bert</a></p>
<p><a href="https://github.com/hanxiao/bert-as-service" target="_blank" rel="noopener">Github:bert-as-service</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ganjinzero.github.io/2019/01/21/用Keras构造日文的神经网络语言模型/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="GanjinZero">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GanjinZero.github.io">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/01/21/用Keras构造日文的神经网络语言模型/" class="post-title-link" itemprop="url">用Keras构造日文的神经网络语言模型</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-01-21 12:41:40 / 修改时间：15:04:25" itemprop="dateCreated datePublished" datetime="2019-01-21T12:41:40+08:00">2019-01-21</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文介绍了语言模型，并介绍如何用MeCab和Keras实现一个日文的神经网络语言模型。（为什么是日文呢？纯属作者兴趣）</p>
<h1 id="基于神经网络的语言模型"><a href="#基于神经网络的语言模型" class="headerlink" title="基于神经网络的语言模型"></a>基于神经网络的语言模型</h1><p>依据Wikepedia，语言模型的定义是“句子们的概率分布”。给定一个长度为m的句子，则可以有概率</p>
<script type="math/tex; mode=display">
    P(w_1,...,w_m)</script><p>由条件概率公式有</p>
<script type="math/tex; mode=display">
    P(w_1,...w_m) = \prod_{i=1}^mP(w_i|w_1,...w_{i-1})</script><p>n-gram模型假设，第i个词语的概率分布只和前面固定的n个词有关（Markov性），那么就有</p>
<script type="math/tex; mode=display">
    P(w_1,...w_m) = \prod_{i=1}^mP(w_i|w_1,...w_{i-1}) \approx \prod_{i=1}^mP(w_i|w_{i-(n-1)},...,w_{i-1})</script><p>所以估计</p>
<script type="math/tex; mode=display">
P(w_1,...w_m)</script><p>的任务变成了估计</p>
<script type="math/tex; mode=display">
    P(w_i|w_{i-(n-1)},...,w_{i-1})</script><p>用传统的统计方法面临着</p>
<ul>
<li>维度灾难（当n变大，存储空间不够）</li>
<li>n元组并不会在语料库中全部出现</li>
</ul>
<p>所以这里使用神经网络近似函数</p>
<script type="math/tex; mode=display">
    P(w_i|w_{i-(n-1)},...,w_{i-1})</script><p>神经网络方法解决了如上两个困难</p>
<ul>
<li>当n变大，神经网络的参数以线性级别增长</li>
<li>n元组虽然没有全部出现，但词向量可以捕捉到不同的词可能代表的相似的含义</li>
</ul>
<p>一个传统的基于神经网络的模型结构如下图所示：<br><img src="/images/neural_language_model.png" alt="traditional"></p>
<h1 id="用MeCab实现日语分词"><a href="#用MeCab实现日语分词" class="headerlink" title="用MeCab实现日语分词"></a>用MeCab实现日语分词</h1><p>MeCab(めかぶ)是一款日语分词工具。Linux用户可以用如下指令安装MeCab:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install mecab mecab-ipadic-utf8 libmecab-dev swig</span><br><span class="line">pip install mecab-python3</span><br></pre></td></tr></table></figure></p>
<p>MeCab可以对一个句子进行分词，并分析各词的词性。对于句子“すもももももももものうち”有<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">すもももももももものうち</span><br><span class="line">すもも  名詞,一般,*,*,*,*,すもも,スモモ,スモモ</span><br><span class="line">も      助詞,係助詞,*,*,*,*,も,モ,モ</span><br><span class="line">もも    名詞,一般,*,*,*,*,もも,モモ,モモ</span><br><span class="line">も      助詞,係助詞,*,*,*,*,も,モ,モ</span><br><span class="line">もも    名詞,一般,*,*,*,*,もも,モモ,モモ</span><br><span class="line">の      助詞,連体化,*,*,*,*,の,ノ,ノ</span><br><span class="line">うち    名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ</span><br><span class="line">EOS</span><br></pre></td></tr></table></figure></p>
<p>为了将分析的结果转化为分词结果，可用如下的<code>mecab_to_text</code>函数，则会输出“すもも も もも も もも の うち”。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mecab_to_text</span><span class="params">(sentence_list)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param sentence_list: A list of sentences or one single sentence.</span></span><br><span class="line"><span class="string">    :return: A list of segmented sentences.</span></span><br><span class="line"><span class="string">    :note: Use mecab to segment a list of sentences or one single sentence in Japanese.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">import</span> MeCab</span><br><span class="line">    mecab = MeCab.Tagger(<span class="string">"-Ochasen"</span>)</span><br><span class="line"></span><br><span class="line">    single_flag = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(sentence_list, str):</span><br><span class="line">        sentence_list = [sentence_list]</span><br><span class="line">        single_flag = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    ret_list = []</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentence_list:</span><br><span class="line">        text_list = []</span><br><span class="line">        m = mecab.parseToNode(sentence)</span><br><span class="line">        <span class="keyword">while</span> m:</span><br><span class="line">            text_list.append(m.surface)</span><br><span class="line">            m = m.next</span><br><span class="line">        seg_sentence = <span class="string">" "</span>.join(text_list).strip()</span><br><span class="line">        ret_list.append(seg_sentence)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> single_flag:</span><br><span class="line">        <span class="keyword">return</span> ret_list[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">return</span> ret_list</span><br></pre></td></tr></table></figure></p>
<h1 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h1><p>我们需要先构建我们的训练样本，语料库来自日语小说。对语料库中的句子用MeCab进行分词之后，用给定的窗宽k分割出训练集。训练集中的词和词向量进行对应为300维的向量。这样训练集中的每一个x（特征）对应一个(k-1)×300维的矩阵，每一个y（结果）对应一个one-hot的向量。</p>
<h2 id="语料库"><a href="#语料库" class="headerlink" title="语料库"></a>语料库</h2><p>语料库是来自于网络上的日语小说，因为版权因素这里不提供下载。用什么样的小说并不会太影响我们后续的过程。在这里实现了<code>load_text</code>,<code>make_word_dictionary</code>,<code>clear_dictionary</code>；分别用来读入语料库，从分好词的语料库中生成词典，清理词典中在词向量里没有出现的词。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_text</span><span class="params">(use_length=<span class="number">-1</span>, min_len=<span class="number">10</span>)</span>:</span></span><br><span class="line">    start = time.clock()</span><br><span class="line">    japanese_text_path = <span class="string">"H:\\Work\\JapaneseModel\\Japanese_book\\"</span></span><br><span class="line">    text_list = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> use_length == <span class="number">-1</span>:</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(japanese_text_path):</span><br><span class="line">            <span class="keyword">with</span> open(japanese_text_path + file, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                    line_use = line.strip()</span><br><span class="line">                    <span class="keyword">if</span> len(line_use) &gt; min_len:</span><br><span class="line">                        text_list.append(line_use)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        counter = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(japanese_text_path):</span><br><span class="line">            <span class="keyword">with</span> open(japanese_text_path + file, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                    line_use = line.strip()</span><br><span class="line">                    <span class="keyword">if</span> len(line_use) &gt; min_len:</span><br><span class="line">                        text_list.append(line_use)</span><br><span class="line">                    counter += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> counter == use_length:</span><br><span class="line">                        print(<span class="string">"Japanese text loaded %d lines."</span>%use_length)</span><br><span class="line">                        elapsed = time.clock() - start</span><br><span class="line">                        print(<span class="string">"Time used:"</span>, round(elapsed, <span class="number">3</span>))</span><br><span class="line">                        <span class="keyword">return</span> text_list</span><br><span class="line">                </span><br><span class="line">    print(<span class="string">"Japanese text loaded all lines."</span>)</span><br><span class="line">    elapsed = time.clock() - start</span><br><span class="line">    print(<span class="string">"Time used:"</span>, round(elapsed, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text_list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_word_dictionary</span><span class="params">(split_text_list, lower_bound=<span class="number">100</span>)</span>:</span></span><br><span class="line">    start = time.clock()</span><br><span class="line">    </span><br><span class="line">    word_dictionary = dict()</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> split_text_list:</span><br><span class="line">        sentence_use = sentence.split(<span class="string">" "</span>)</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sentence_use:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> word <span class="keyword">in</span> word_dictionary:</span><br><span class="line">                word_dictionary[word] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                word_dictionary[word] += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">    print(<span class="string">"Word dictionary established."</span>)</span><br><span class="line">    elapsed = time.clock() - start</span><br><span class="line">    print(<span class="string">"Time used:"</span>, round(elapsed, <span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> lower_bound &gt; <span class="number">0</span>:</span><br><span class="line">        pop_list = []</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> word_dictionary:</span><br><span class="line">            <span class="keyword">if</span> word_dictionary[word] &lt; lower_bound:</span><br><span class="line">                pop_list.append(word)</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> pop_list:</span><br><span class="line">            word_dictionary.pop(word)</span><br><span class="line">            </span><br><span class="line">    word_list = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word_dictionary:</span><br><span class="line">        word_list.append(word)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">return</span> word_list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clear_dictionary</span><span class="params">(dictionary, embedding_dictionary)</span>:</span></span><br><span class="line">    ret_list = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> dictionary:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> embedding_dictionary:</span><br><span class="line">            ret_list.append(word)</span><br><span class="line"><span class="keyword">return</span> ret_list</span><br></pre></td></tr></table></figure></p>
<p>实现了这几个函数以后，就可以用如下的方式读入语料库。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">japanese_text = load_text(use_text_length)</span><br><span class="line">split_japanese_text = mecab_to_text(japanese_text)</span><br><span class="line">dictionary = make_word_dictionary(split_japanese_text, lower_bound=<span class="number">10</span>)</span><br><span class="line">dictionary = clear_dictionary(dictionary, embeddings_index)</span><br></pre></td></tr></table></figure></p>
<h2 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h2><p>我们使用facebook在fastText项目中预训练好的日语300维词向量，下载地址点击<a href="https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.ja.300.vec.gz" target="_blank" rel="noopener">这里</a>。因为该文件的第一行保存了词向量文件的信息，你应该手动删除该行，然后用<code>load_embedding</code>函数来读取词向量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_embedding</span><span class="params">()</span>:</span></span><br><span class="line">    start = time.clock()</span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Total 2000000 words in this embedding file, 300-d. It is float16 type.</span></span><br><span class="line"><span class="string">    The first line is "2000000 300".</span></span><br><span class="line"><span class="string">    You should delete this line.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    EMBEDDING_FILE = <span class="string">'H:\\Work\\cc.ja.300.vec'</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_coefs</span><span class="params">(word, *arr)</span>:</span> <span class="keyword">return</span> word, np.asarray(arr, dtype=<span class="string">'float16'</span>)</span><br><span class="line">    embeddings_index = dict(get_coefs(*o.strip().split(<span class="string">" "</span>)) <span class="keyword">for</span> o <span class="keyword">in</span> open(EMBEDDING_FILE, <span class="string">'r'</span>, encoding=<span class="string">"utf-8"</span>))</span><br><span class="line">    </span><br><span class="line">    elapsed = time.clock() - start</span><br><span class="line">    print(<span class="string">"Word vectors loaded."</span>)</span><br><span class="line">    print(<span class="string">"Time used:"</span>, round(elapsed, <span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> embeddings_index</span><br></pre></td></tr></table></figure></p>
<h2 id="生成训练集"><a href="#生成训练集" class="headerlink" title="生成训练集"></a>生成训练集</h2><p>假设我们的窗宽为k，那么我们的训练集由k-1个词组成x_train，由之后连接的词组成y_train。如果k=3，我们语料库中的一个句子为“a bb ccc d”,　其中a、bb、ccc、d分别是4个词。那么我们将这个句子前面连接k-1=2个“space”，结尾连接一个“eol”，扩充为“space space a bb ccc d eof”。这样可以得到如下的训练样本：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">x1</th>
<th style="text-align:left">x2</th>
<th style="text-align:left">y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">space</td>
<td style="text-align:left">space</td>
<td style="text-align:left">a</td>
</tr>
<tr>
<td style="text-align:left">space</td>
<td style="text-align:left">a</td>
<td style="text-align:left">bb</td>
</tr>
<tr>
<td style="text-align:left">a</td>
<td style="text-align:left">bb</td>
<td style="text-align:left">ccc</td>
</tr>
<tr>
<td style="text-align:left">bb</td>
<td style="text-align:left">ccc</td>
<td style="text-align:left">d</td>
</tr>
<tr>
<td style="text-align:left">ccc</td>
<td style="text-align:left">d</td>
<td style="text-align:left">eol</td>
</tr>
</tbody>
</table>
</div>
<p><code>generate_train</code>函数实现了上述生成训练集的算法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_train</span><span class="params">(window, end_index, text_seq)</span>:</span></span><br><span class="line">    prefix = [<span class="number">0</span>] * (window - <span class="number">1</span>)</span><br><span class="line">    suffix = [end_index]</span><br><span class="line">    x_list = []</span><br><span class="line">    y_list = []</span><br><span class="line">    <span class="keyword">for</span> seq <span class="keyword">in</span> text_seq:</span><br><span class="line">        <span class="keyword">if</span> len(seq) &gt; <span class="number">1</span>:</span><br><span class="line">            seq_use = prefix + seq + suffix</span><br><span class="line">            <span class="comment"># print(seq_use)</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(seq_use) - window + <span class="number">1</span>):</span><br><span class="line">                x_list.append(seq_use[i: i + window - <span class="number">1</span>])</span><br><span class="line">                y_list.append(seq_use[i + window - <span class="number">1</span>])</span><br><span class="line">                <span class="comment"># print(seq_use[i: i + window])</span></span><br><span class="line">    <span class="keyword">return</span> x_list, y_list</span><br></pre></td></tr></table></figure></p>
<h2 id="构建神经网络模型"><a href="#构建神经网络模型" class="headerlink" title="构建神经网络模型"></a>构建神经网络模型</h2><p>和传统的神经网络语言模型有所不同：先将x映射为词向量，连接双层BiLSTM作为隐藏层，再连接一个Softmax来预测下一个词是什么。在Keras中，实现BiLSTM非常容易。因为<code>CuDNNLSTM</code>的实现比<code>LSTM</code>要快很多，推荐安装cudnn来使用这个函数。加入了一些<code>Dropout</code>层来避免过拟合。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Model</span></span><br><span class="line">inp = Input(shape=(window - <span class="number">1</span>,))</span><br><span class="line">x = Embedding(nb_words, <span class="number">300</span>, trainable = <span class="keyword">True</span>, weights=[embedding_matrix])(inp)</span><br><span class="line">x = Bidirectional(CuDNNLSTM(<span class="number">128</span>, return_sequences=<span class="keyword">True</span>))(x)</span><br><span class="line">x = Dropout(<span class="number">0.1</span>)(x)</span><br><span class="line">x = Bidirectional(CuDNNLSTM(<span class="number">128</span>, return_sequences=<span class="keyword">False</span>))(x)</span><br><span class="line">x = Dropout(<span class="number">0.1</span>)(x)</span><br><span class="line">x = Dense(<span class="number">128</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = Dropout(<span class="number">0.1</span>)(x)</span><br><span class="line">x = Dense(nb_words, activation=<span class="string">"softmax"</span>)(x)</span><br><span class="line">model = Model(inputs=inp, outputs=x)</span><br><span class="line">opt = keras.optimizers.Adam(lr=<span class="number">0.001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, </span><br><span class="line">                            epsilon=<span class="keyword">None</span>, decay=<span class="number">0.0</span>, amsgrad=<span class="keyword">False</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, </span><br><span class="line">              optimizer=opt, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">history = LossHistory()</span><br><span class="line"></span><br><span class="line">epoch_nb = <span class="number">80</span> <span class="comment"># 40 is enough</span></span><br><span class="line">batch = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=batch, epochs=epoch_nb, verbose=<span class="number">1</span>,</span><br><span class="line">          validation_data=(x_test, y_test), callbacks=[history])</span><br></pre></td></tr></table></figure></p>
<h2 id="随机生成句子"><a href="#随机生成句子" class="headerlink" title="随机生成句子"></a>随机生成句子</h2><p>用<code>predict_random_sentence</code>函数来生成随机句子，其中的<code>reverse_index</code>保存了从语料库生成的词典中的词和序号的一一对应。若将[0,0,0,0]更改为其他数字，即可生成给定开头的句子。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_random_sentence</span><span class="params">(new=[<span class="number">0</span>] * <span class="params">(window - <span class="number">1</span>)</span>)</span>:</span></span><br><span class="line">    sentence = reverse_index[new[<span class="number">0</span>]] + reverse_index[new[<span class="number">1</span>]] + reverse_index[new[<span class="number">2</span>]] + reverse_index[new[<span class="number">3</span>]]</span><br><span class="line">    <span class="keyword">while</span> new[<span class="number">-1</span>] != end_index:</span><br><span class="line">        prob = model.predict(np.asarray([new]))[<span class="number">0</span>]</span><br><span class="line">        new_predict = int(random.choices(word_ind, weights=prob)[<span class="number">0</span>])</span><br><span class="line">        sentence += reverse_index[new_predict]</span><br><span class="line">        new = new[<span class="number">1</span>:] + [new_predict]</span><br><span class="line">    <span class="keyword">return</span> sentence</span><br><span class="line"></span><br><span class="line">predict_random_sentence([<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><p>保存模型到本地，以后就可以直接调用，避免重复训练。上文中提到的tokenizer和神经网络模型都需要保存。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"../result/tokenizer.pkl"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> handle:</span><br><span class="line">    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)</span><br><span class="line">model.save(<span class="string">'../model/language_model.model'</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h1><p>我们训练了80个epoch，使用了20000句话进行训练，选择的窗宽为5。以下是从日文语言模型中随机生成的一些句子。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&apos;「なんだろう。僕が仕事を休みになり、でもまあ……見てた」&apos;</span><br><span class="line">&apos;アグライアはグラスをじっと見つめた。&apos;</span><br><span class="line">&apos;それにしても、それを使って、ジークをから表情になって猫のように《さ》がを受けた。&apos;</span><br><span class="line">&apos;森そうだ、そんなことか」&apos;</span><br><span class="line">&apos;真剣で命をように、そのの人は、辻宮氏はだいたい邸にてあげた《と？》みをうとした。「そんな顔だって今？」&apos;</span><br><span class="line">&apos;佳澄ちゃんが……俺とさっきに言わせて下さい。&apos;</span><br><span class="line">&apos;沙耶「まあ、沙耶ねえ先に戻ることにになってきます？」&apos;</span><br><span class="line">&apos;「最近はどうしてそういうつもりじゃないでしょうね」&apos;</span><br></pre></td></tr></table></figure></p>
<p>简单的翻译一下生成的句子（日语水平比较烂，可能翻译错了）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&apos;怎么说呢。我虽然下班了，但还是……看到了&apos;</span><br><span class="line">&apos;Agria凝视着玻璃杯&apos;</span><br><span class="line">&apos;即使如此，使用它，Sieg看来像猫一样的表情接受了さ&apos;</span><br><span class="line">&apos;像树林啊，是这样吗&apos;</span><br><span class="line">这句话实在不太通顺……</span><br><span class="line">&apos;佳澄酱，请给我说下刚才的事情&apos;</span><br><span class="line">&apos;沙耶：“嘛，沙耶先回去了啊？”&apos;</span><br><span class="line">&apos;最近为什么不打算这样做了呢&apos;</span><br></pre></td></tr></table></figure></p>
<p>总体来说，该语言模型可以生成出一些通顺的话语。以上都是从空句子开始生成的，也可以改变生成句子的开头。</p>
<h1 id="项目地址及参考文献"><a href="#项目地址及参考文献" class="headerlink" title="项目地址及参考文献"></a>项目地址及参考文献</h1><p>完整的项目代码见<a href="https://github.com/GanjinZero/Deep-Learning-Playground/tree/master/code/Language%20Model" target="_blank" rel="noopener">GitHub</a><br><a href="https://en.wikipedia.org/wiki/Language_model" target="_blank" rel="noopener">Language_model</a><br><a href="http://taku910.github.io/mecab/" target="_blank" rel="noopener">MeCab</a><br><a href="https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md" target="_blank" rel="noopener">fastText</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ganjinzero.github.io/2019/01/17/在PyPI上发布并更新自己的python-package/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="GanjinZero">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GanjinZero.github.io">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/01/17/在PyPI上发布并更新自己的python-package/" class="post-title-link" itemprop="url">在PyPI上发布并更新自己的python package</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-01-17 10:24:12" itemprop="dateCreated datePublished" datetime="2019-01-17T10:24:12+08:00">2019-01-17</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-11 14:52:17" itemprop="dateModified" datetime="2019-03-11T14:52:17+08:00">2019-03-11</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="将package整理成如下形式"><a href="#将package整理成如下形式" class="headerlink" title="将package整理成如下形式"></a>将package整理成如下形式</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/example_pkg</span><br><span class="line">  /example_pkg</span><br><span class="line">    __init__.py</span><br><span class="line">  setup.py</span><br><span class="line">  LICENSE</span><br><span class="line">  README.md</span><br></pre></td></tr></table></figure>
<h1 id="编辑setup-py"><a href="#编辑setup-py" class="headerlink" title="编辑setup.py"></a>编辑setup.py</h1><p>注意每次更新要更新版本号。</p>
<h1 id="生成distribution-archives"><a href="#生成distribution-archives" class="headerlink" title="生成distribution archives"></a>生成distribution archives</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py sdist bdist_wheel</span><br></pre></td></tr></table></figure>
<h1 id="上传distribution-archives"><a href="#上传distribution-archives" class="headerlink" title="上传distribution archives"></a>上传distribution archives</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">twine upload dist/*</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m twine upload dist/*</span><br></pre></td></tr></table></figure>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://packaging.python.org/tutorials/packaging-projects/" target="_blank" rel="noopener">Packaging Python Projects</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ganjinzero.github.io/2019/01/15/利用pyserverchan推送程序输出/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="GanjinZero">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GanjinZero.github.io">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/01/15/利用pyserverchan推送程序输出/" class="post-title-link" itemprop="url">利用pyserverchan推送程序输出</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-01-15 11:46:01 / 修改时间：12:17:20" itemprop="dateCreated datePublished" datetime="2019-01-15T11:46:01+08:00">2019-01-15</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p>在深度学习的过程中，训练时间一般很长，如果可以将训练结果自动推送到微信上，可以省去不少的麻烦。Server酱是一个向微信发送自定义信息的服务，我将该服务打包成了pyserverchan，可以让python用户简单的调用。</p>
<h1 id="注册Server酱"><a href="#注册Server酱" class="headerlink" title="注册Server酱"></a>注册Server酱</h1><p>进入<a href="http://sc.ftqq.com/3.version" target="_blank" rel="noopener">Server酱</a>官网，只需要两个步骤即可完成注册。</p>
<ul>
<li>在主页登陆GitHub账号，获得一个SCKEY</li>
<li>点击微信推送，进行绑定</li>
</ul>
<p>至此，你已经获得了一个SCKEY。在python中这样设置你的user_URL<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user_URL = <span class="string">'https://sc.ftqq.com/'</span> + SCKEY + <span class="string">'.send'</span></span><br></pre></td></tr></table></figure></p>
<h1 id="使用pyserverchan"><a href="#使用pyserverchan" class="headerlink" title="使用pyserverchan"></a>使用pyserverchan</h1><p>安装pyserverchan<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyserverchan</span><br></pre></td></tr></table></figure></p>
<p>在Python中发送文字，图片（png格式），Markdown格式文件。（至多64K）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyserverchan <span class="keyword">import</span> pyserver</span><br><span class="line">svc = pyserver.ServerChan(user_URL)</span><br><span class="line">svc.output_to_weixin(<span class="string">"ATestMessage."</span>)</span><br><span class="line">svc.output_to_weixin_picture(<span class="string">"http://sc.ftqq.com/static/image/bottom_logo.png"</span>)</span><br><span class="line">svc.output_to_weixin_markdown(<span class="string">"J:/pyserverchan/README.md"</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="使用例子"><a href="#使用例子" class="headerlink" title="使用例子"></a>使用例子</h1><p>当训练神经网络时，想将训练完的准确率发送至微信，加入如下代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">train_result = <span class="string">'Accuracy on train:'</span> + str(round(acc_train, <span class="number">4</span>) * <span class="number">100</span>) + <span class="string">"%"</span> + os.linesep + os.linesep</span><br><span class="line">train_result += <span class="string">'Accuracy on test:'</span> + str(round(acc_test, <span class="number">4</span>) * <span class="number">100</span>) + <span class="string">"%"</span></span><br><span class="line">svc.output_to_weixin(<span class="string">'Train done.'</span>, train_result) <span class="comment"># 第一个参数是发送的文章标题，第二个参数是发送的文章内容</span></span><br></pre></td></tr></table></figure></p>
<p>微信端即可收到如下结果<br><img src="/images/1.jpg" alt=""></p>
<h1 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h1><ul>
<li><a href="https://github.com/GanjinZero/pyserverchan" target="_blank" rel="noopener">GitHub</a></li>
<li><a href="https://pypi.org/project/pyserverchan/" target="_blank" rel="noopener">PyPi</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">GanjinZero</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/GanjinZero" title="GitHub &rarr; https://github.com/GanjinZero" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:yuanz17@mails.tsinghua.edu.cn" title="E-Mail &rarr; mailto:yuanz17@mails.tsinghua.edu.cn" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">GanjinZero</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v6.7.0</div>



        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=6.7.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  



  





  

  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: "AMS"
      }
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
      for (i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
  overflow: auto hidden;
}
</style><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

</body>
</html>
